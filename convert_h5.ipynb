{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './datasets/trainnew'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m ori_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./datasets/trainnew\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      7\u001b[0m out_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./datasets/trainnew_h5\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 8\u001b[0m all_subject \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mori_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './datasets/trainnew'"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "ori_path = r'./datasets/trainnew'\n",
    "out_path = r'./datasets/trainnew_h5'\n",
    "all_subject = os.listdir(ori_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/songzhiyun/software/anaconda3/envs/segsr/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "from utils.parse_image_file import parse_image\n",
    "from utils.blur_kernel_ops import calc_extended_patch_size, parse_kernel\n",
    "from utils.pad import target_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(subject):\n",
    "    image, slice_separation, _,  blur_fwhm, _, _, _, _ = parse_image(\n",
    "        os.path.join(ori_path, subject), 3.0, 0.75\n",
    "    )\n",
    "    image = image.squeeze() # shape (x, y, z, 2)\n",
    "    if len(image.shape) == 3:\n",
    "        image = image[..., np.newaxis]\n",
    "    \n",
    "    # upsample the image using b-spline interpolation\n",
    "    img_data = image[...,0]\n",
    "    label_data = image[...,1]\n",
    "    upsampled_img_data = scipy.ndimage.zoom(img_data, (1,1,4), order=3)  # order=3 for cubic B-spline\n",
    "    upsampled_label_data = scipy.ndimage.zoom(label_data, (1,1,4), order=0)  # order=0 for nearest interpolation\n",
    "    image = np.stack([upsampled_img_data, upsampled_label_data], axis=-1)\n",
    "    \n",
    "    blur_kernel = parse_kernel(None, 'rf-pulse-slr', blur_fwhm)\n",
    "    img_hr = image[...,:1]\n",
    "    label_hr = image[...,1:].astype('uint8')\n",
    "    image_x = torch.from_numpy(image.transpose(2, 3, 0, 1)) # z, channel, x, y\n",
    "    image_x_rgb = image_x[:, 0:1, ...]\n",
    "    image_x_rgb = F.conv2d(image_x_rgb, blur_kernel, padding=\"same\").numpy()\n",
    "\n",
    "    image_y = torch.from_numpy(image.transpose(2, 3, 1, 0)) # z, channel, y, x\n",
    "    image_y_rgb = image_y[:, 0:1, ...]\n",
    "    image_y_rgb = F.conv2d(image_y_rgb, blur_kernel, padding=\"same\").numpy()\n",
    "    return img_hr, label_hr, image_x_rgb, image_y_rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject in all_subject:\n",
    "    img_hr, label_hr, image_x_rgb, image_y_rgb = preprocess(subject)\n",
    "    with h5py.File(os.path.join(out_path, subject + '.h5'), 'w') as f:\n",
    "        f.create_dataset('img_hr', data=img_hr)\n",
    "        f.create_dataset('label_hr', data=label_hr)\n",
    "        f.create_dataset('image_x_rgb', data=image_x_rgb)\n",
    "        f.create_dataset('image_y_rgb', data=image_y_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zeroonenorm(data):\n",
    "    data =  (data - np.min(data)) / (np.max(data) - np.min(data))\n",
    "    data = (data * 255.0)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_intensity(volume, percentils=[0.5, 99.5], bins_num=256, norm=False):\n",
    "    volume[volume < 0] = 0\n",
    "    obj_volume = volume[np.where(volume > 0)]\n",
    "    min_value = np.percentile(obj_volume, percentils[0])\n",
    "    max_value = np.percentile(obj_volume, percentils[1])\n",
    "\n",
    "    if bins_num == 0:\n",
    "        obj_volume = (obj_volume - min_value) / (max_value - min_value).astype(np.float32)\n",
    "    else:\n",
    "        obj_volume = np.round((obj_volume - min_value) / (max_value - min_value) * (bins_num - 1))\n",
    "        obj_volume[np.where(obj_volume < 1)] = 1\n",
    "        obj_volume[np.where(obj_volume > (bins_num - 1))] = bins_num - 1\n",
    "\n",
    "    volume[np.where(volume > 0)] = obj_volume\n",
    "    volume = volume.astype(obj_volume.dtype)\n",
    "    if norm:\n",
    "        volume = volume.astype(float) / (bins_num - 1)\n",
    "\n",
    "    return volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from scipy.interpolate import RegularGridInterpolator\n",
    "\n",
    "def get_dims(shape, max_channels=10):\n",
    "    \"\"\"Get the number of dimensions and channels from the shape of an array.\n",
    "    The number of dimensions is assumed to be the length of the shape, as long as the shape of the last dimension is\n",
    "    inferior or equal to max_channels (default 3).\n",
    "    :param shape: shape of an array. Can be a sequence or a 1d numpy array.\n",
    "    :param max_channels: maximum possible number of channels.\n",
    "    :return: the number of dimensions and channels associated with the provided shape.\n",
    "    example 1: get_dims([150, 150, 150], max_channels=10) = (3, 1)\n",
    "    example 2: get_dims([150, 150, 150, 3], max_channels=10) = (3, 3)\n",
    "    example 3: get_dims([150, 150, 150, 15], max_channels=10) = (4, 1), because 5>3\"\"\"\n",
    "    if shape[-1] <= max_channels:\n",
    "        n_dims = len(shape) - 1\n",
    "        n_channels = shape[-1]\n",
    "    else:\n",
    "        n_dims = len(shape)\n",
    "        n_channels = 1\n",
    "    return n_dims, n_channels\n",
    "\n",
    "def get_ras_axes(aff, n_dims=3):\n",
    "    \"\"\"This function finds the RAS axes corresponding to each dimension of a volume, based on its affine matrix.\n",
    "    :param aff: affine matrix Can be a 2d numpy array of size n_dims*n_dims, n_dims+1*n_dims+1, or n_dims*n_dims+1.\n",
    "    :param n_dims: number of dimensions (excluding channels) of the volume corresponding to the provided affine matrix.\n",
    "    :return: two numpy 1d arrays of length n_dims, one with the axes corresponding to RAS orientations,\n",
    "    and one with their corresponding direction.\n",
    "    \"\"\"\n",
    "    aff_inverted = np.linalg.inv(aff)\n",
    "    img_ras_axes = np.argmax(np.absolute(aff_inverted[0:n_dims, 0:n_dims]), axis=0)\n",
    "    for i in range(n_dims):\n",
    "        if i not in img_ras_axes:\n",
    "            unique, counts = np.unique(img_ras_axes, return_counts=True)\n",
    "            incorrect_value = unique[np.argmax(counts)]\n",
    "            img_ras_axes[np.where(img_ras_axes == incorrect_value)[0][-1]] = i\n",
    "\n",
    "    return img_ras_axes\n",
    "\n",
    "def align_volume_to_ref(volume, aff, aff_ref=None, return_aff=False, n_dims=None, return_copy=True):\n",
    "    \"\"\"This function aligns a volume to a reference orientation (axis and direction) specified by an affine matrix.\n",
    "    :param volume: a numpy array\n",
    "    :param aff: affine matrix of the floating volume\n",
    "    :param aff_ref: (optional) affine matrix of the target orientation. Default is identity matrix.\n",
    "    :param return_aff: (optional) whether to return the affine matrix of the aligned volume\n",
    "    :param n_dims: (optional) number of dimensions (excluding channels) of the volume. If not provided, n_dims will be\n",
    "    inferred from the input volume.\n",
    "    :param return_copy: (optional) whether to return the original volume or a copy. Default is copy.\n",
    "    :return: aligned volume, with corresponding affine matrix if return_aff is True.\n",
    "    \"\"\"\n",
    "\n",
    "    # work on copy\n",
    "    new_volume = volume.copy() if return_copy else volume\n",
    "    aff_flo = aff.copy()\n",
    "\n",
    "    # default value for aff_ref\n",
    "    if aff_ref is None:\n",
    "        aff_ref = np.eye(4)\n",
    "\n",
    "    # extract ras axes\n",
    "    if n_dims is None:\n",
    "        n_dims, _ = get_dims(new_volume.shape)\n",
    "    ras_axes_ref = get_ras_axes(aff_ref, n_dims=n_dims)\n",
    "    ras_axes_flo = get_ras_axes(aff_flo, n_dims=n_dims)\n",
    "\n",
    "    # align axes\n",
    "    aff_flo[:, ras_axes_ref] = aff_flo[:, ras_axes_flo]\n",
    "    for i in range(n_dims):\n",
    "        if ras_axes_flo[i] != ras_axes_ref[i]:\n",
    "            new_volume = np.swapaxes(new_volume, ras_axes_flo[i], ras_axes_ref[i])\n",
    "            swapped_axis_idx = np.where(ras_axes_flo == ras_axes_ref[i])\n",
    "            ras_axes_flo[swapped_axis_idx], ras_axes_flo[i] = ras_axes_flo[i], ras_axes_flo[swapped_axis_idx]\n",
    "\n",
    "    # align directions\n",
    "    dot_products = np.sum(aff_flo[:3, :3] * aff_ref[:3, :3], axis=0)\n",
    "    for i in range(n_dims):\n",
    "        if dot_products[i] < 0:\n",
    "            new_volume = np.flip(new_volume, axis=i)\n",
    "            aff_flo[:, i] = - aff_flo[:, i]\n",
    "            aff_flo[:3, 3] = aff_flo[:3, 3] - aff_flo[:3, i] * (new_volume.shape[i] - 1)\n",
    "\n",
    "    if return_aff:\n",
    "        return new_volume, aff_flo\n",
    "    else:\n",
    "        return new_volume\n",
    "\n",
    "def load_volume(path_volume, im_only=True, squeeze=True, dtype=None, aff_ref=None):\n",
    "    \"\"\"\n",
    "    Load volume file.\n",
    "    :param path_volume: path of the volume to load. Can either be a nii, nii.gz, mgz, or npz format.\n",
    "    If npz format, 1) the variable name is assumed to be 'vol_data',\n",
    "    2) the volume is associated with an identity affine matrix and blank header.\n",
    "    :param im_only: (optional) if False, the function also returns the affine matrix and header of the volume.\n",
    "    :param squeeze: (optional) whether to squeeze the volume when loading.\n",
    "    :param dtype: (optional) if not None, convert the loaded volume to this numpy dtype.\n",
    "    :param aff_ref: (optional) If not None, the loaded volume is aligned to this affine matrix.\n",
    "    The returned affine matrix is also given in this new space. Must be a numpy array of dimension 4x4.\n",
    "    :return: the volume, with corresponding affine matrix and header if im_only is False.\n",
    "    \"\"\"\n",
    "    assert path_volume.endswith(('.nii', '.nii.gz', '.mgz', '.npz')), 'Unknown data file: %s' % path_volume\n",
    "\n",
    "    if path_volume.endswith(('.nii', '.nii.gz', '.mgz')):\n",
    "        x = nib.load(path_volume)\n",
    "        if squeeze:\n",
    "            volume = np.squeeze(x.get_fdata())\n",
    "        else:\n",
    "            volume = x.get_fdata()\n",
    "        aff = x.affine\n",
    "        header = x.header\n",
    "    else:  # npz\n",
    "        volume = np.load(path_volume)['vol_data']\n",
    "        if squeeze:\n",
    "            volume = np.squeeze(volume)\n",
    "        aff = np.eye(4)\n",
    "        header = nib.Nifti1Header()\n",
    "    if dtype is not None:\n",
    "        if 'int' in dtype:\n",
    "            volume = np.round(volume)\n",
    "        volume = volume.astype(dtype=dtype)\n",
    "\n",
    "    # align image to reference affine matrix\n",
    "    if aff_ref is not None:\n",
    "        n_dims, _ = get_dims(list(volume.shape), max_channels=10)\n",
    "        volume, aff = align_volume_to_ref(volume, aff, aff_ref=aff_ref, return_aff=True, n_dims=n_dims)\n",
    "\n",
    "    if im_only:\n",
    "        return volume\n",
    "    else:\n",
    "        return volume, aff, header\n",
    "\n",
    "def save_volume(volume, aff, header, path, dtype=None, n_dims=3):\n",
    "    \"\"\"\n",
    "    Save a volume.\n",
    "    :param volume: volume to save\n",
    "    :param aff: affine matrix of the volume to save. If aff is None, the volume is saved with an identity affine matrix.\n",
    "    aff can also be set to 'FS', in which case the volume is saved with the affine matrix of FreeSurfer outputs.\n",
    "    :param header: header of the volume to save. If None, the volume is saved with a blank header.\n",
    "    :param path: path where to save the volume.\n",
    "    :param res: (optional) update the resolution in the header before saving the volume.\n",
    "    :param dtype: (optional) numpy dtype for the saved volume.\n",
    "    :param n_dims: (optional) number of dimensions, to avoid confusion in multi-channel case. Default is None, where\n",
    "    n_dims is automatically inferred.\n",
    "    \"\"\"\n",
    "\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    if '.npz' in path:\n",
    "        np.savez_compressed(path, vol_data=volume)\n",
    "    else:\n",
    "        if header is None:\n",
    "            header = nib.Nifti1Header()\n",
    "        if isinstance(aff, str):\n",
    "            if aff == 'FS':\n",
    "                aff = np.array([[-1, 0, 0, 0], [0, 0, 1, 0], [0, -1, 0, 0], [0, 0, 0, 1]])\n",
    "        elif aff is None:\n",
    "            aff = np.eye(4)\n",
    "        nifty = nib.Nifti1Image(volume, aff, header)\n",
    "        if dtype is not None:\n",
    "            if 'int' in dtype:\n",
    "                volume = np.round(volume)\n",
    "            volume = volume.astype(dtype=dtype)\n",
    "            nifty.set_data_dtype(dtype)\n",
    "        nib.save(nifty, path)\n",
    "\n",
    "def resample_volume(volume, aff, new_vox_size, interpolation='linear', blur=True):\n",
    "    \"\"\"This function resizes the voxels of a volume to a new provided size, while adjusting the header to keep the RAS\n",
    "    :param volume: a numpy array\n",
    "    :param aff: affine matrix of the volume\n",
    "    :param new_vox_size: new voxel size (3 - element numpy vector) in mm\n",
    "    :param interpolation: (optional) type of interpolation. Can be 'linear' or 'nearest. Default is 'linear'.\n",
    "    :return: new volume and affine matrix\n",
    "    \"\"\"\n",
    "\n",
    "    pixdim = np.sqrt(np.sum(aff * aff, axis=0))[:-1]\n",
    "    new_vox_size = np.array(new_vox_size)\n",
    "    factor = pixdim / new_vox_size\n",
    "    sigmas = 0.25 / factor\n",
    "    sigmas[factor > 1] = 0  # don't blur if upsampling\n",
    "    if not blur:\n",
    "        sigmas = (0,0,0)\n",
    "\n",
    "    volume_filt = gaussian_filter(volume, sigmas)\n",
    "\n",
    "    # volume2 = zoom(volume_filt, factor, order=1, mode='reflect', prefilter=False)\n",
    "    x = np.arange(0, volume_filt.shape[0])\n",
    "    y = np.arange(0, volume_filt.shape[1])\n",
    "    z = np.arange(0, volume_filt.shape[2])\n",
    "\n",
    "    my_interpolating_function = RegularGridInterpolator((x, y, z), volume_filt, method=interpolation)\n",
    "\n",
    "    start = - (factor - 1) / (2 * factor)\n",
    "    step = 1.0 / factor\n",
    "    stop = start + step * np.ceil(volume_filt.shape * factor)\n",
    "\n",
    "    xi = np.arange(start=start[0], stop=stop[0], step=step[0])\n",
    "    yi = np.arange(start=start[1], stop=stop[1], step=step[1])\n",
    "    zi = np.arange(start=start[2], stop=stop[2], step=step[2])\n",
    "    xi[xi < 0] = 0\n",
    "    yi[yi < 0] = 0\n",
    "    zi[zi < 0] = 0\n",
    "    xi[xi > (volume_filt.shape[0] - 1)] = volume_filt.shape[0] - 1\n",
    "    yi[yi > (volume_filt.shape[1] - 1)] = volume_filt.shape[1] - 1\n",
    "    zi[zi > (volume_filt.shape[2] - 1)] = volume_filt.shape[2] - 1\n",
    "\n",
    "    xig, yig, zig = np.meshgrid(xi, yi, zi, indexing='ij', sparse=True)\n",
    "    volume2 = my_interpolating_function((xig, yig, zig))\n",
    "\n",
    "    aff2 = aff.copy()\n",
    "    for c in range(3):\n",
    "        aff2[:-1, c] = aff2[:-1, c] / factor[c]\n",
    "    aff2[:-1, -1] = aff2[:-1, -1] - np.matmul(aff2[:-1, :-1], 0.5 * (factor - 1))\n",
    "\n",
    "    return volume2, aff2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "ori_path = r\"/mnt/INSPUR_storage/songzhiyun/project/BoneTumorSeg/data/Brain_datasets/bspline_sr\"\n",
    "tmp_path = r'/home/songzhiyun/project/BoneTumorSeg/data/Liver_datasets/trainnew_sr_resample_temp'\n",
    "out_path = r'/home/songzhiyun/project/BoneTumorSeg/data/Brain_datasets/bspline_sr_h5'\n",
    "os.makedirs(tmp_path, exist_ok=True)\n",
    "all_subject = os.listdir(ori_path)\n",
    "all_subject = [x for x in all_subject if x.endswith('_img.nii.gz')]\n",
    "for subject in all_subject:\n",
    "    # ori_t1_data, aff_t1, hdr = load_volume(os.path.join(ori_path, subject), im_only=False, dtype='float')\n",
    "    # pixdim = np.sqrt(np.sum(aff_t1 * aff_t1, axis=0))[:-1]\n",
    "    # t1_data_lr, aff_t1_lr = resample_volume(ori_t1_data, aff_t1, [1.04167,1.04167,1.5])\n",
    "    # save_volume(t1_data_lr, aff_t1_lr, hdr, os.path.join(tmp_path, subject))\n",
    "\n",
    "    # ori_t2_data, aff_t2, hdr = load_volume(os.path.join(ori_path, subject.replace('_img', '_seg')), im_only=False, dtype='uint8')\n",
    "    # t2_data_lr, aff_t2_lr = resample_volume(ori_t2_data, aff_t2, [1.04167,1.04167,1.5], interpolation='nearest')\n",
    "    # save_volume(t2_data_lr, aff_t2_lr, hdr, os.path.join(tmp_path, subject.replace('_img', '_seg')))\n",
    "\n",
    "    # ori_t3_data, aff_t3, hdr = load_volume(os.path.join(ori_path, subject.replace('_img', '_uncertainty')), im_only=False, dtype='float')\n",
    "    # t3_data_lr, aff_t3_lr = resample_volume(ori_t3_data, aff_t3, [1.04167,1.04167,1.5])\n",
    "    # save_volume(t3_data_lr, aff_t3_lr, hdr, os.path.join(tmp_path, subject.replace('_img', '_uncertainty')))\n",
    "    \n",
    "\n",
    "    image, _, _,  _, _, _, _, _ = parse_image(\n",
    "        os.path.join(ori_path, subject), 4.0, 1.0\n",
    "    )\n",
    "    image = zeroonenorm(image)\n",
    "    seg, _, _,  _, _, _, _, _ = parse_image(\n",
    "        os.path.join(ori_path, subject.replace('_img', '_seg')), 4.0, 1.0\n",
    "    )\n",
    "    seg = seg.astype('uint8')\n",
    "    if os.path.exists(os.path.join(ori_path, subject.replace('_img', '_uncertainty'))):\n",
    "        uncertainty, _, _,  _, _, _, _, _ = parse_image(\n",
    "            os.path.join(ori_path, subject.replace('_img', '_uncertainty')), 4.0, 1.0\n",
    "        )\n",
    "        uncertainty = (zeroonenorm(uncertainty) * 255.0).astype('uint8')\n",
    "    else:\n",
    "        uncertainty = np.zeros_like(seg)\n",
    "    \n",
    "    with h5py.File(os.path.join(out_path, subject.replace('_img.nii.gz', '_0000.h5')), 'w') as f:\n",
    "        f.create_dataset('img', data=image)\n",
    "        f.create_dataset('seg', data=seg)\n",
    "        f.create_dataset('uncertainty', data=uncertainty)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "ori_path = r'/home/songzhiyun/project/BoneTumorSeg/code/nnUNet/DATASET/nnUNet_raw/Dataset510_BoneTumor/imagesTr'\n",
    "tmp_path = r'/home/songzhiyun/project/BoneTumorSeg/code/nnUNet/DATASET/nnUNet_raw/Dataset510_BoneTumor/imagesTr'\n",
    "os.makedirs(tmp_path, exist_ok=True)\n",
    "all_subject = os.listdir(ori_path)\n",
    "all_subject = [x for x in all_subject if x.endswith('.nii.gz')]\n",
    "for subject in all_subject:\n",
    "    ori_t1_data, aff_t1, hdr = load_volume(os.path.join(ori_path, subject), im_only=False, dtype='float')\n",
    "    pixdim = np.sqrt(np.sum(aff_t1 * aff_t1, axis=0))[:-1]\n",
    "    t1_data_lr, aff_t1_lr = resample_volume(ori_t1_data, aff_t1, [1.04167,1.04167,1.5])\n",
    "    save_volume(t1_data_lr, aff_t1_lr, hdr, os.path.join(tmp_path, subject))\n",
    "\n",
    "    ori_t2_data, aff_t2, hdr = load_volume(os.path.join(ori_path.replace('imagesTr', 'labelsTr'), subject.replace('_0000', '')), im_only=False, dtype='uint8')\n",
    "    t2_data_lr, aff_t2_lr = resample_volume(ori_t2_data, aff_t2, [1.04167,1.04167,1.5], interpolation='nearest')\n",
    "    save_volume(t2_data_lr, aff_t2_lr, hdr, os.path.join(ori_path.replace('imagesTr', 'labelsTr'), subject.replace('_0000', '')))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'116-dicom_0000_img.nii.gz'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "szy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
